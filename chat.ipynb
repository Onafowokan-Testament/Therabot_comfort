{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NLTK PREPROCESSING INPUT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from collections.abc import MutableMapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections.abc\n",
    "\n",
    "# üëáÔ∏è add attributes to `collections` module\n",
    "# before you import the package that causes the issue\n",
    "collections.Mapping = collections.abc.Mapping\n",
    "collections.MutableMapping = collections.abc.MutableMapping\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "collections.MutableSet = collections.abc.MutableSet\n",
    "collections.Callable = collections.abc.Callable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    tokenize_word = word_tokenize(sentence)\n",
    "    return tokenize_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bag_of_words(tokenize_sentence, all_words):\n",
    "    bag = np.zeros(len(all_words), dtype = np.float32)\n",
    "\n",
    "    for ind,word in enumerate(all_words):\n",
    "        if word in tokenize_sentence:\n",
    "            bag[ind] = 1.0\n",
    "    return bag\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_sentence(sentence,stemmer= PorterStemmer()):\n",
    "    stemmed_sentence = []\n",
    "    ignore_words = [\"!\", \"?\",\",\" , \".\"]\n",
    "    for word in sentence:\n",
    "        if word not in ignore_words:\n",
    "            word = word.lower()\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            stemmed_sentence.append(stemmed_word)\n",
    "    return stemmed_sentence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "vocabulary = []\n",
    "\n",
    "\n",
    "with open (\"intents.json\", 'r') as file:\n",
    "    intents = json.load(file)\n",
    "for intent in intents[\"intents\"]:\n",
    "    tag = intent[\"tag\"]\n",
    "    tags.append(tag)\n",
    "    sentences = intent[\"patterns\"]\n",
    "    for items in sentences:\n",
    "        \n",
    "        w = tokenize_sentence(items)\n",
    "        vocabulary.append(w)\n",
    "        w = stem_sentence(w)\n",
    "        xy.append((w,tag))\n",
    "        all_words.extend(w)\n",
    "\n",
    "\n",
    "ignore_words = [\"!\", \"?\",\",\" , \".\"]\n",
    "set_of_word = [i.lower() for word in vocabulary for i  in word if i not in ignore_words]\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "\n",
    "with open (\"tags.json\", 'w') as file:\n",
    "    json.dump(tags, file)\n",
    "\n",
    "with open (\"all_words.json\", 'w') as file:\n",
    "    json.dump(all_words, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'there', 'hello', 'hey', 'good', 'morning', 'i', 'want', 'to', 'schedule', 'a', 'cleaning', 'service', 'can', 'i', 'book', 'a', 'cleaning', 'appointment', 'how', 'can', 'i', 'set', 'up', 'a', 'cleaning', 'appointment', 'schedule', 'a', 'cleaning', 'for', 'tomorrow', 'what', 'janitorial/cleaning', 'services', 'do', 'you', 'offer', 'tell', 'me', 'about', 'your', 'cleaning', 'services', 'what', 'secure', 'and', 'logistic', 'services', 'do', 'you', 'provide', 'tell', 'me', 'about', 'your', 'executive', 'car', 'hire', 'service', 'what', 'business', 'services', 'do', 'you', 'offer', 'do', 'you', 'provide', 'recruitment', 'and', 'training', 'solutions', 'what', 'industries', 'do', 'you', 'specialize', 'in', 'how', 'much', 'does', 'your', 'janitorial', 'cleaning', 'service', 'cost', 'what', 'are', 'the', 'rates', 'for', 'home', 'cleaning', 'tell', 'me', 'about', 'your', 'post-construction', 'cleaning', 'pricing', 'how', 'much', 'does', 'outsourcing', 'cost', 'what', 'are', 'the', 'fees', 'for', 'business', 'report', 'services', 'what', 'are', 'the', 'charges', 'for', 'executive', 'car', 'hire', 'tell', 'me', 'about', 'your', 'journey', 'management', 'pricing', 'what', 'is', 'the', 'cost', 'of', 'your', 'fleet', 'management', 'service', 'do', 'you', 'have', 'special', 'packages', 'for', 'safety', 'equipment', 'rental', 'i', 'need', 'to', 'cancel', 'my', 'cleaning', 'appointment', 'how', 'can', 'i', 'cancel', 'my', 'booking', 'cancel', 'my', 'executive', 'car', 'hire', 'reservation', 'can', 'i', 'reschedule', 'my', 'training', 'session', 'i', 'had', 'a', 'bad', 'experience', 'with', 'your', 'cleaning', 'service', 'i', 'want', 'to', 'complain', 'about', 'the', 'logistic', 'service', 'provided', 'your', 'executive', 'car', 'hire', 'was', 'not', 'up', 'to', 'the', 'mark', 'i', 'faced', 'issues', 'with', 'your', 'recruitment', 'process', 'thank', 'you', 'for', 'the', 'great', 'cleaning', 'service', 'thanks', 'for', 'the', 'logistic', 'support', 'your', 'executive', 'car', 'hire', 'made', 'my', 'journey', 'comfortable', 'i', 'appreciate', 'your', 'business', 'assistance', 'what', 'sets', 'arc', 'solution', 'apart', 'in', 'terms', 'of', 'knowledge', 'and', 'experience', 'how', 'does', 'arc', 'solution', 'provide', 'enormous', 'logistics', 'support', 'how', 'is', 'arc', 'solution', \"'s\", 'team', 'committed', 'to', 'providing', 'excellent', 'services', 'how', 'does', 'arc', 'solution', 'ensure', 'technical', 'competence', 'in', 'its', 'services', 'what', 'makes', 'arc', 'solution', 'an', 'emblem', 'of', 'quality', 'how', 'does', 'arc', 'solution', 'prioritize', 'customer', 'satisfaction', 'does', 'arc', 'solution', 'provide', '24/7', 'customer', 'support', 'how', 'does', 'arc', 'solution', 'assure', 'security', 'in', 'its', 'services', 'what', 'are', 'your', 'contact', 'details', 'how', 'can', 'i', 'reach', 'you', 'tell', 'me', 'your', 'phone', 'numbers', 'and', 'email', 'address']\n"
     ]
    }
   ],
   "source": [
    "print(set_of_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (sequence, tag )in xy:\n",
    "    bag = bag_of_words(sequence, all_words)\n",
    "    train_x.append(bag)\n",
    "\n",
    "    label = tags.index(tag)\n",
    "    train_y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainy one hot encoding\n",
    "hot_output = []\n",
    "output_code = [0 for i in range(len(tags))]\n",
    "for tag_no in train_y:\n",
    "    output_tag = output_code[:]\n",
    "    output_tag[tag_no] = 1\n",
    "    hot_output.append(output_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_x)\n",
    "train_y = np.array(hot_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 121)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(40, activation = \"relu\", input_shape =(None, train_x.shape[0], train_x.shape[1]) ))\n",
    "model.add(tf.keras.layers.Dense(35,activation = \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(len(tags), activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 47, 121) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 47, 121), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 121).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 47, 121) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 47, 121), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 121).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 47, 121) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 47, 121), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 121).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 47, 121) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 47, 121), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 121).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 5ms/step - loss: 2.2000 - accuracy: 0.1489\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1561 - accuracy: 0.1489\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1188 - accuracy: 0.1915\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0832 - accuracy: 0.2128\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.0523 - accuracy: 0.2553\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.0181 - accuracy: 0.2979\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.9856 - accuracy: 0.3830\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.9537 - accuracy: 0.3830\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.9193 - accuracy: 0.4043\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.8861 - accuracy: 0.4681\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8527 - accuracy: 0.5106\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8170 - accuracy: 0.5319\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7794 - accuracy: 0.5957\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.7433 - accuracy: 0.5957\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.7045 - accuracy: 0.5957\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6632 - accuracy: 0.6170\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6198 - accuracy: 0.6383\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5770 - accuracy: 0.6809\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.5326 - accuracy: 0.6809\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4849 - accuracy: 0.6809\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.4380 - accuracy: 0.7021\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3920 - accuracy: 0.7021\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3430 - accuracy: 0.7021\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.2941 - accuracy: 0.7021\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2438 - accuracy: 0.7234\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1952 - accuracy: 0.7234\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1445 - accuracy: 0.7234\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0943 - accuracy: 0.7447\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0461 - accuracy: 0.7872\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9975 - accuracy: 0.7872\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9509 - accuracy: 0.8085\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9038 - accuracy: 0.8298\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8594 - accuracy: 0.8511\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8138 - accuracy: 0.8511\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7722 - accuracy: 0.8511\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7308 - accuracy: 0.8511\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.8511\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6563 - accuracy: 0.8511\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6210 - accuracy: 0.8511\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5868 - accuracy: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f0a141d50>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs = 40, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
