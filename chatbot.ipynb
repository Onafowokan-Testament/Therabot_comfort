{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections.abc\n",
    "collections.Mapping = collections.abc.Mapping\n",
    "collections.MutableMapping = collections.abc.MutableMapping\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Model was constructed with shape (None, None, 47, 121) for input KerasTensor.*\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def check_sentence(sentence,vocab):\n",
    "    word_freq = Counter(vocab)\n",
    "    prob = {}\n",
    "    total = sum(word_freq.values())\n",
    "    for k in word_freq:\n",
    "        prob[k] = word_freq[k]/total \n",
    "    question = []\n",
    "    for word in sentence:\n",
    "        word = word.lower()\n",
    "        if word in word:\n",
    "            question.append(word)\n",
    "        else:\n",
    "            sim = [1-(textdistance.Jaccard(qval=2).distance(v,word)) for v in word_freq.keys()]\n",
    "            df = pd.DataFrame.from_dict(prob, orient='index').reset_index()\n",
    "            df = df.rename(columns={'index':'Word', 0:'Prob'})\n",
    "            df['Similarity'] = sim\n",
    "            output = df.sort_values(['Similarity', 'Prob'], ascending=False).head()\n",
    "            return(output)   \n",
    "\n",
    "def tokenize(question):\n",
    "    return word_tokenize(question)\n",
    "    \n",
    "def stem_word(word, stemmer = PorterStemmer()):\n",
    "    return stemmer.stem(word)\n",
    "\n",
    "def data():\n",
    "    with open(\"tags.json\", \"r\") as file:\n",
    "        tags = json.load(file)\n",
    "    with open(\"all_words.json\", \"r\") as file:\n",
    "        all_words = json.load(file)\n",
    "    return tags,all_words\n",
    "\n",
    "\n",
    "def bag_of_words(vocab,tok_sentence):\n",
    "    bag = np.zeros(len(vocab), dtype=np.float32)\n",
    "    for ind, word in enumerate(vocab):\n",
    "        if word in tok_sentence:\n",
    "            bag[ind] = 1.0\n",
    "    return bag\n",
    "\n",
    "def predict(input, tags):\n",
    "    model = tf.keras.models.load_model(\"model1\")\n",
    "    prediction = tags[np.argmax(model.predict(input))]\n",
    "    return prediction\n",
    "      \n",
    "\n",
    "def correct_sentence(question):\n",
    "    pass\n",
    "\n",
    "def question_understood(question):\n",
    "    pass\n",
    "\n",
    "def get_answer(prediction):\n",
    "    with open(\"intents.json\", \"r\") as data:\n",
    "        intents = json.load(data)\n",
    "        for tg in intents[\"intents\"]:\n",
    "            if tg['tag'] == prediction:\n",
    "                choice = random.choice(tg[\"responses\"])\n",
    "                break\n",
    "    return choice\n",
    "\n",
    "\n",
    "def process_question(question, vocab):\n",
    "    tok_ques = tokenize(question)\n",
    "    stemmed_words = [stem_word(s) for s in tok_ques if s not in [',', '.', '!', '?', ',']]\n",
    "    word_bag = np.array([1.0 if word in stemmed_words else 0.0 for word in vocab], dtype=np.float32)\n",
    "    word_bag = np.expand_dims(word_bag, axis=0)\n",
    "    return word_bag\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to arc solution chatbot!\n",
      "User:\t hi\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 47, 121) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 47, 121), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 121).\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "Answer:\t Customer satisfaction is our top priority, and we strive to exceed our customers' expectations in every project we undertake.\n",
      "User:\t good day\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 47, 121) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 47, 121), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 121).\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "Answer:\t Hi! How may I help you?\n",
      "User:\t i need to know your services\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 47, 121) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 47, 121), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 121).\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "Answer:\t I'm sorry for the issues with the recruitment process. Let's discuss your concerns and find a resolution.\n",
      "User:\t .\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 47, 121) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 47, 121), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 121).\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "Answer:\t Arc Solution is an emblem of quality due to our unwavering commitment to excellence and customer satisfaction.\n",
      "Thanks for using this bot!\n"
     ]
    }
   ],
   "source": [
    "tags, vocab = data()\n",
    "chat = True\n",
    "print(\"Welcome to arc solution chatbot!\")\n",
    "while(chat):\n",
    "    question = input(\" \")\n",
    "    if (question == \"end\"):\n",
    "        print(\"Thanks for using this bot!\")\n",
    "        chat = False\n",
    "        break\n",
    "    print(\"User:\\t\", question)\n",
    "    answer = get_answer(predict(process_question(question,vocab),tags))\n",
    "    print(\"Answer:\\t\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.check_sentence(sentence, vocab)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
