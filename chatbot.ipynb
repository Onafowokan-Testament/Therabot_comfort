{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections.abc\n",
    "collections.Mapping = collections.abc.Mapping\n",
    "collections.MutableMapping = collections.abc.MutableMapping\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Model was constructed with shape (None, None, 47, 121) for input KerasTensor.*\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model name 'distilbert-base-cased' was not found in model name list (distilbert-base-uncased, distilbert-base-uncased-distilled-squad). We assumed 'distilbert-base-cased' was a path or url but couldn't find tokenizer filesat this path or url.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "model = tf.keras.models.load_model(\"model2\")\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "def is_unanswerable_question(question):\n",
    "    inputs = tokenizer.encode_plus(question, return_tensors=\"tf\", add_special_tokens=True)\n",
    "    start_logits, end_logits = model(inputs['input_ids'])\n",
    "\n",
    "    start_probabilities = tf.nn.softmax(start_logits, axis=1)\n",
    "    end_probabilities = tf.nn.softmax(end_logits, axis=1)\n",
    "\n",
    "    answerable_confidence = tf.reduce_max(start_probabilities).numpy()\n",
    "    return answerable_confidence < confidence_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize(question):\n",
    "    return word_tokenize(question)\n",
    "    \n",
    "def stem_word(word, stemmer = PorterStemmer()):\n",
    "    return stemmer.stem(word)\n",
    "\n",
    "def data():\n",
    "    with open(\"tags.json\", \"r\") as file:\n",
    "        tags = json.load(file)\n",
    "    with open(\"all_words.json\", \"r\") as file:\n",
    "        all_words = json.load(file)\n",
    "    return tags,all_words\n",
    "\n",
    "\n",
    "def bag_of_words(vocab,tok_sentence):\n",
    "    bag = np.zeros(len(vocab), dtype=np.float32)\n",
    "    for ind, word in enumerate(vocab):\n",
    "        if word in tok_sentence:\n",
    "            bag[ind] = 1.0\n",
    "    return bag\n",
    "\n",
    "def predict(input, tags):\n",
    "    model = tf.keras.models.load_model(\"model2\")\n",
    "    prediction = tags[np.argmax(model.predict(input))]\n",
    "    max_prob = max(model.predict(input)[0])\n",
    "    return prediction, max_prob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def question_understood(question):\n",
    "    pass\n",
    "\n",
    "def get_answer(prediction):\n",
    "    with open(\"intents.json\", \"r\") as data:\n",
    "        intents = json.load(data)\n",
    "        for tg in intents[\"intents\"]:\n",
    "            if tg['tag'] == prediction:\n",
    "                choice = random.choice(tg[\"responses\"])\n",
    "                break\n",
    "    return choice\n",
    "def auto_correct_sentence(sentence):\n",
    "    corrected_tokens = [spell.correction(token) for token in sentence]\n",
    "    return corrected_tokens\n",
    "\n",
    "\n",
    "def process_question(question, vocab):\n",
    "    tok_ques = tokenize(question)\n",
    "    stemmed_words = [stem_word(s) for s in tok_ques if s not in [',', '.', '!', '?', ',']]\n",
    "    cor_ques = auto_correct_sentence(stemmed_words)\n",
    "    print(cor_ques)\n",
    "    word_bag = np.array([1.0 if word in cor_ques else 0.0 for word in vocab], dtype=np.float32)\n",
    "    word_bag = np.expand_dims(word_bag, axis=0)\n",
    "    return word_bag\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to arc solution chatbot!\n",
      "Thanks for using this bot!\n"
     ]
    }
   ],
   "source": [
    "tags, vocab = data()\n",
    "chat = True\n",
    "spell = SpellChecker()\n",
    "spell.word_frequency.load_words(vocab)\n",
    "\n",
    "\n",
    "user = st.chat_message(\"user\")\n",
    "bot = st.chat_message(\"assistant\")\n",
    "print(\"Welcome to arc solution chatbot!\")\n",
    "while(chat):\n",
    "\n",
    "    prompt = st.chat_input(\"Enter something\")\n",
    "    if prompt:\n",
    "        user.write(\"User:\\t\", prompt)\n",
    "        prd, max_prob = predict(process_question(prompt,vocab),tags)\n",
    "        answer = get_answer(prd)\n",
    "        bot.write(\"Answer:\\t\", answer)\n",
    "        \n",
    "        # prd, max_prob = predict(process_question(question,vocab),tags)\n",
    "    if (question == \"end\"):\n",
    "        print(\"Thanks for using this bot!\")\n",
    "        chat = False\n",
    "        break\n",
    "    # print(\"User:\\t\", question)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # print(\"Answer:\\t\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
